{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "from torchvision import models\n",
    "import cv2\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor():\n",
    "    \"\"\"\n",
    "    1. 提取目标层特征\n",
    "    2. register 目标层梯度\n",
    "    \"\"\"\n",
    "    def __init__(self, model, target_layers):\n",
    "        self.model = model\n",
    "        self.model_features = model.features\n",
    "        self.target_layers = target_layers\n",
    "        self.gradients = list()\n",
    "    def save_gradient(self, grad):\n",
    "        self.gradients.append(grad)\n",
    "    def get_gradients(self):\n",
    "        return self.gradients\n",
    "    def __call__(self, x):\n",
    "        target_activations = list()\n",
    "        self.gradients = list()\n",
    "        for name, module in self.model_features._modules.items(): #遍历的方式遍历网络的每一层\n",
    "            x = module(x) #input 会经过遍历的每一层\n",
    "            if name in self.target_layers: #设个条件，如果到了你指定的层， 则继续\n",
    "                x.register_hook(self.save_gradient) #利用hook来记录目标层的梯度\n",
    "                target_activations += [x] #这里只取得目标层的features\n",
    "        x = x.view(x.size(0), -1) #reshape成 全连接进入分类器\n",
    "        x = self.model.classifier(x)#进入分类器\n",
    "        return target_activations, x,\n",
    "\n",
    "        \n",
    "def preprocess_image(img):\n",
    "    \"\"\"\n",
    "    预处理层\n",
    "    将图像进行标准化处理\n",
    "    \"\"\"\n",
    "    mean = [0.485, 0.456, 0.406] \n",
    "    stds = [0.229, 0.224, 0.225]\n",
    "    preprocessed_img = img.copy()[:, :, ::-1] # BGR > RGB\n",
    "    \n",
    "    #标准化处理， 将bgr三层都处理\n",
    "    for i in range(3):\n",
    "\n",
    "        preprocessed_img[:, :, i] = preprocessed_img[:, :, i] - mean[i]\n",
    "        preprocessed_img[:, :, i] = preprocessed_img[:, :, i] / stds[i]\n",
    "        \n",
    "    preprocessed_img = \\\n",
    "        np.ascontiguousarray(np.transpose(preprocessed_img, (2, 0, 1))) #transpose HWC > CHW\n",
    "    preprocessed_img = t.from_numpy(preprocessed_img) #totensor\n",
    "    preprocessed_img.unsqueeze_(0)\n",
    "    input = t.tensor(preprocessed_img, requires_grad=True)\n",
    "    \n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_cam_on_image(img, mask):\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255*mask), cv2.COLORMAP_JET) #利用色彩空间转换将heatmap凸显\n",
    "    heatmap = np.float32(heatmap)/255 #归一化\n",
    "    print(heatmap.shape)\n",
    "    cam = heatmap + np.float32(img) #将heatmap 叠加到原图\n",
    "    cam = cam / np.max(cam)\n",
    "    cv2.imwrite('GradCam_test.jpg', np.uint8(255 * cam))#生成图像\n",
    "    # # 将图像的三个通道分离\n",
    "    # red_channel = img[:, :, 0]\n",
    "    # green_channel = img[:, :, 1]\n",
    "    # blue_channel = img[:, :, 2]\n",
    "\n",
    "    # # 创建一个 1x3 的图像网格\n",
    "    # plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # # 绘制红色通道\n",
    "    # plt.subplot(1, 3, 1)\n",
    "    # plt.imshow(red_channel, cmap='Reds')\n",
    "    # plt.title('Red Channel')\n",
    "    # plt.axis('off')\n",
    "\n",
    "    # # 绘制绿色通道\n",
    "    # plt.subplot(1, 3, 2)\n",
    "    # plt.imshow(green_channel, cmap='Greens')\n",
    "    # plt.title('Green Channel')\n",
    "    # plt.axis('off')\n",
    "\n",
    "    # # 绘制蓝色通道\n",
    "    # plt.subplot(1, 3, 3)\n",
    "    # plt.imshow(blue_channel, cmap='Blues')\n",
    "    # plt.title('Blue Channel')\n",
    "    # plt.axis('off')\n",
    "\n",
    "    # plt.show()\n",
    "    # cam = cam[:, :, ::-1] #BGR > RGB\n",
    "    # plt.figure(figsize=(10, 10))\n",
    "    # plt.imshow(np.uint8(255*cam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradCam():\n",
    "    \"\"\"\n",
    "    GradCam主要执行\n",
    "    1.提取特征(调用FeatureExtractor)\n",
    "    2.反向传播求目标层梯度\n",
    "    3.实现目标层的CAM图\n",
    "    \"\"\"\n",
    "    def __init__(self, model, target_layer_names):\n",
    "        self.model = model\n",
    "\n",
    "\n",
    "        self.extractor = FeatureExtractor(self.model, target_layer_names)\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    def __call__(self, input):\n",
    "        features, output = self.extractor(input) #这里的feature 对应的就是目标层的输出， output是图像经过分类网络的输出\n",
    "        output.data\n",
    "        one_hot = output.max() #取1000个类中最大的值\n",
    "            \n",
    "        self.model.features.zero_grad() #梯度清零\n",
    "        self.model.classifier.zero_grad() #梯度清零\n",
    "        one_hot.backward(retain_graph=True) #反向传播之后，为了取得目标层梯度\n",
    "        \n",
    "        grad_val = self.extractor.get_gradients()[-1].data.numpy()\n",
    "        #调用函数get_gradients(),  得到目标层求得的梯\n",
    "        \n",
    "        target = features[-1] \n",
    "        #features 目前是list 要把里面relu层的输出取出来, 也就是我们要的目标层 shape(1, 512, 14, 14)\n",
    "        target = target.data.numpy()[0, :] #(1, 512, 14, 14) > (512, 14, 14) \n",
    "        \n",
    "        \n",
    "        weights = np.mean(grad_val, axis = (2, 3))[0, :] #array shape (512, ) 求出relu梯度的 512层 每层权重\n",
    "        \n",
    "        cam = np.zeros(target.shape[1:]) #做一个空白map，待会将值填上\n",
    "        #(14, 14)  shape(512, 14, 14)tuple  索引[1:] 也就是从14开始开始\n",
    "        \n",
    "        #for loop的方式将平均后的权重乘上目标层的每个feature map， 并且加到刚刚生成的空白map上\n",
    "        for i, w in enumerate(weights): \n",
    "            cam += w * target[i, :, :] \n",
    "            #w * target[i, :, :]\n",
    "            #target[i, :, :] = array:shape(14, 14)\n",
    "            #w = 512个的权重均值 shape(512, )\n",
    "            #每个均值分别乘上target的feature map\n",
    "            #在放到空白的14*14上（cam)\n",
    "            #最终 14*14的空白map 会被填满\n",
    "        cam = cv2.resize(cam, (224, 224)) #将14*14的featuremap 放大回224*224\n",
    "        cam = cam - np.min(cam)\n",
    "        cam = cam  / np.max(cam)\n",
    "        return cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_cam = GradCam(model = models.vgg16(pretrained=True), target_layer_names = [\"29\"])\n",
    "\n",
    "#使用预训练vgg16\n",
    "#我们的目标层取第29层relu, relu层只保留有用的结果， 所以取其层最能突显出特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19296/600010312.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input = t.tensor(preprocessed_img, requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('/home/zzy/Python projects/Earthquake waveform/my_project/ZzyNet-master/gorilla.jpg') #读取图像\n",
    "img = np.float32(cv2.resize(img, (224, 224))) / 255 #为了丢到vgg16要求的224*224 先进行缩放并且归一化\n",
    "input = preprocess_image(img)\n",
    "mask = grad_cam(input)\n",
    "show_cam_on_image(img, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
