{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from pyts.image import GramianAngularField\n",
    "from pyts.image import MarkovTransitionField\n",
    "import librosa\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import os\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path='/root/autodl-tmp/Python projects/Dataset/3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "短时傅里叶变换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def STFT(data, n_fft=100, hop_length=5,window='hann'):\n",
    "    num_samples, num_features, num_time_steps = data.shape\n",
    "    stft_data = np.zeros((num_samples, num_features, 1 + n_fft // 2,601), dtype=np.float32)\n",
    "    data = np.array(data, dtype=np.float32)\n",
    "    for i in range(num_samples):\n",
    "        for k in range(num_features):\n",
    "            # 计算STFT\n",
    "            stft_data[i][k] = librosa.stft(data[i][k], n_fft=n_fft, \n",
    "                                           hop_length=hop_length,win_length=n_fft, \n",
    "                                           window=window)\n",
    "    return stft_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1708, 3, 3000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2005/1821536388.py:8: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  stft_data[i][k] = librosa.stft(data[i][k], n_fft=n_fft,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1708, 3, 51, 601])\n"
     ]
    }
   ],
   "source": [
    "# data = torch.load(base_path+'/tensor dataset/natural_test_dataset.pt')\n",
    "# print(data.shape)\n",
    "# STFT_data=[]\n",
    "# for i in range(data.shape[0]):\n",
    "#     stft_data=data[i:i+1,:,:]\n",
    "#     stft_images = STFT(stft_data)\n",
    "#     STFT_data.append(stft_images)\n",
    "# STFT_data=torch.tensor(STFT_data).squeeze(dim=1)\n",
    "# print(STFT_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stft_tensor_save(data):\n",
    "    #将变换后的tensor保存\n",
    "    STFT_data=[]\n",
    "    for i in range(data.shape[0]):\n",
    "        stft_data=data[i:i+1,:,:]\n",
    "        stft_images = STFT(stft_data)\n",
    "        STFT_data.append(stft_images)\n",
    "    STFT_data=torch.tensor(STFT_data).squeeze(dim=1)\n",
    "    return STFT_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2005/1821536388.py:8: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  stft_data[i][k] = librosa.stft(data[i][k], n_fft=n_fft,\n"
     ]
    }
   ],
   "source": [
    "loaded_natural_train = torch.load(base_path+'/tensor dataset/natural_train_dataset.pt')\n",
    "natural_train_STFT=stft_tensor_save(loaded_natural_train)\n",
    "torch.save(natural_train_STFT, base_path+'/processed_data/STFT_51_601/natural_train_STFT.pt')\n",
    "del loaded_natural_train,natural_train_STFT\n",
    "loaded_natural_test = torch.load(base_path+'/tensor dataset/natural_test_dataset.pt')\n",
    "natural_test_STFT=stft_tensor_save(loaded_natural_test)\n",
    "torch.save(natural_test_STFT, base_path+'/processed_data/STFT_51_601/natural_test_STFT.pt')\n",
    "del loaded_natural_test,natural_test_STFT\n",
    "loaded_ep_train = torch.load(base_path+'/tensor dataset/ep_train_dataset.pt')\n",
    "ep_train_STFT=stft_tensor_save(loaded_ep_train)\n",
    "torch.save(ep_train_STFT, base_path+'/processed_data/STFT_51_601/ep_train_STFT.pt')\n",
    "del loaded_ep_train,ep_train_STFT\n",
    "loaded_ep_test = torch.load(base_path+'/tensor dataset/ep_test_dataset.pt')\n",
    "ep_test_STFT=stft_tensor_save(loaded_ep_test)\n",
    "torch.save(ep_test_STFT, base_path+'/processed_data/STFT_51_601/ep_test_STFT.pt')\n",
    "del loaded_ep_test,ep_test_STFT\n",
    "loaded_ss_train = torch.load(base_path+'/tensor dataset/ss_train_dataset.pt')\n",
    "ss_train_STFT=stft_tensor_save(loaded_ss_train)\n",
    "torch.save(ss_train_STFT, base_path+'/processed_data/STFT_51_601/ss_train_STFT.pt')\n",
    "del loaded_ss_train,ss_train_STFT\n",
    "loaded_ss_test = torch.load(base_path+'/tensor dataset/ss_test_dataset.pt')\n",
    "ss_test_STFT=stft_tensor_save(loaded_ss_test)\n",
    "torch.save(ss_test_STFT, base_path+'/processed_data/STFT_51_601/ss_test_STFT.pt')\n",
    "del loaded_ss_test,ss_test_STFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 打印重新排列后的张量大小\n",
    "# print(STFT_data.size())  # 输出: torch.Size([1794, 72, 72, 3])\n",
    "# #可视化\n",
    "# sample_index = 300  # 选择一个样本进行展示\n",
    "# plt.figure(figsize=(12, 4))\n",
    "# stft_display= librosa.amplitude_to_db(np.abs(STFT_data[sample_index][0] .numpy()), ref=np.max)\n",
    "# librosa.display.specshow(stft_display, sr=50,hop_length=3,x_axis=\"s\", y_axis=\"hz\")  \n",
    "# # plt.colorbar(format=\"%+2.0f dB\")\n",
    "# # plt.ylim(0, 25)\n",
    "# plt.tight_layout()\n",
    "# # plt.title(f'Sample {sample_index}')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(complex_norm_tape, aspect='auto')\n",
    "# # ,interpolation='bicubic'\n",
    "# plt.xlabel('Time (1/50th sec. per tick)')\n",
    "# plt.ylabel('Frequency (Hz)')\n",
    "# plt.gca().invert_yaxis()\n",
    "# # plt.yscale('log')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MFCC倒谱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MFCC(data, sample_rate=50,n_mfcc=13,n_fft=142, hop_length=42):\n",
    "    data = np.array(data, dtype=np.float32)\n",
    "    num_samples, num_features, num_time_steps = data.shape\n",
    "    mfcc_data = np.zeros((num_samples, num_features, 40, 72), dtype=np.float32)\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        for k in range(num_features):\n",
    "            # 计算MFCC\n",
    "            mfcc= librosa.feature.mfcc(y=data[i][k], sr=sample_rate,n_mfcc=n_mfcc,win_length=n_fft,hop_length=hop_length,n_fft=n_fft)\n",
    "            #一阶差分\n",
    "            delta_mfcc = librosa.feature.delta(data=mfcc)\n",
    "            #二阶差分\n",
    "            delta2_mfcc = librosa.feature.delta(data=mfcc, order=2)\n",
    "            # 计算音频信号每帧的对数能量\n",
    "            log_energy = librosa.amplitude_to_db(librosa.feature.rms(y=data[i][k],frame_length=n_fft, hop_length=hop_length))\n",
    "    \n",
    "            mfcc = np.concatenate([mfcc, delta_mfcc, delta2_mfcc,log_energy], axis=0)\n",
    "            mfcc_data[i][k] = mfcc\n",
    "            \n",
    "    return mfcc_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1708, 3, 3000])\n",
      "torch.Size([1708, 3, 40, 72])\n"
     ]
    }
   ],
   "source": [
    "data = torch.load(base_path+'/tensor dataset/natural_test_dataset.pt')\n",
    "print(data.shape)\n",
    "STFT_data=[]\n",
    "for i in range(data.shape[0]):\n",
    "    stft_data=data[i:i+1,:,:]\n",
    "    stft_images = MFCC(stft_data)\n",
    "    STFT_data.append(stft_images)\n",
    "STFT_data=torch.tensor(STFT_data).squeeze(dim=1)\n",
    "print(STFT_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfcc_tensor_save(data):\n",
    "    MFCC_data=[]\n",
    "    for i in range(data.shape[0]):\n",
    "        mfcc_data=data[i:i+1,:,:]\n",
    "        mfcc_images = MFCC(mfcc_data)\n",
    "        MFCC_data.append(mfcc_images)\n",
    "    MFCC_data=torch.tensor(MFCC_data).squeeze(dim=1)\n",
    "    return MFCC_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_natural_train = torch.load(base_path+'/tensor dataset/natural_train_dataset.pt')\n",
    "natural_train_MFCC=mfcc_tensor_save(loaded_natural_train)\n",
    "torch.save(natural_train_MFCC, base_path+'/processed_data/MFCC_40_72/natural_train_MFCC.pt')\n",
    "del loaded_natural_train,natural_train_MFCC\n",
    "loaded_natural_test = torch.load(base_path+'/tensor dataset/natural_test_dataset.pt')\n",
    "natural_test_MFCC=mfcc_tensor_save(loaded_natural_test)\n",
    "torch.save(natural_test_MFCC, base_path+'/processed_data/MFCC_40_72/natural_test_MFCC.pt')\n",
    "del loaded_natural_test,natural_test_MFCC\n",
    "loaded_ep_train = torch.load(base_path+'/tensor dataset/ep_train_dataset.pt')\n",
    "ep_train_MFCC=mfcc_tensor_save(loaded_ep_train)\n",
    "torch.save(ep_train_MFCC, base_path+'/processed_data/MFCC_40_72/ep_train_MFCC.pt')\n",
    "del loaded_ep_train,ep_train_MFCC\n",
    "loaded_ep_test = torch.load(base_path+'/tensor dataset/ep_test_dataset.pt')\n",
    "ep_test_MFCC=mfcc_tensor_save(loaded_ep_test)\n",
    "torch.save(ep_test_MFCC, base_path+'/processed_data/MFCC_40_72/ep_test_MFCC.pt')\n",
    "del loaded_ep_test,ep_test_MFCC\n",
    "loaded_ss_train = torch.load(base_path+'/tensor dataset/ss_train_dataset.pt')\n",
    "ss_train_MFCC=mfcc_tensor_save(loaded_ss_train)\n",
    "torch.save(ss_train_MFCC, base_path+'/processed_data/MFCC_40_72/ss_train_MFCC.pt')\n",
    "del loaded_ss_train,ss_train_MFCC\n",
    "loaded_ss_test = torch.load(base_path+'/tensor dataset/ss_test_dataset.pt')\n",
    "ss_test_MFCC=mfcc_tensor_save(loaded_ss_test)\n",
    "torch.save(ss_test_MFCC, base_path+'/processed_data/MFCC_40_72/ss_test_MFCC.pt')\n",
    "del loaded_ss_test,ss_test_MFCC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(MFCC_data.shape)\n",
    "# # 将MFCC数据可视化\n",
    "# sample_index = 35  # 选择一个样本进行展示\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# plt.title('MFCC')\n",
    "# # 将 PyTorch 张量转换为 NumPy 数组\n",
    "# mfcc_numpy = MFCC_data[sample_index][0].numpy()\n",
    "# librosa.display.specshow(mfcc_numpy)\n",
    "# plt.colorbar()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import os\n",
    "# from torchvision import transforms\n",
    "# from torchvision.utils import save_image\n",
    "\n",
    "# save_tensor=gaf_images_gasf\n",
    "# # Convert the NumPy array to a PyTorch tensor\n",
    "# save_tensor = torch.from_numpy(save_tensor)\n",
    "# # 假设保存的目录为 'imagenet_data'\n",
    "# save_dir = 'E:/processed_data/GASF'\n",
    "\n",
    "# # 创建目录\n",
    "# os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# # 定义一个 torchvision 的转换，将数据转换为范围在 [0, 1] 之间的图像\n",
    "# tensor_to_image = transforms.ToPILImage()\n",
    "\n",
    "# # 保存每个图像\n",
    "# for i in range(save_tensor.shape[0]):\n",
    "#     image_tensor = save_tensor[i]  # 获取单个图像的 tensor\n",
    "#     print(image_tensor.shape)\n",
    "#     image_tensor = torch.clamp(image_tensor, 0, 1)  # 将像素值限制在 [0, 1] 范围内\n",
    "#     image = tensor_to_image(image_tensor)  # 转换为 PIL 图像\n",
    "\n",
    "#     # 构建文件名，例如 'imagenet_data/00001.jpg'\n",
    "#     filename = os.path.join(save_dir, f'{i + 1:05d}.jpg')\n",
    "\n",
    "#     # 保存图像\n",
    "#     image.save(filename)\n",
    "\n",
    "# print(f'图像已保存到 {save_dir} 目录。')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MTF变换马尔可夫过渡场"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def MTF(data):\n",
    "#     num_samples,num_features,num_time_steps = data.shape\n",
    "#     mtf_images = np.zeros((num_samples, num_features, 224, 224))\n",
    "\n",
    "#     for i in range(num_samples):\n",
    "#         mtf = MarkovTransitionField(image_size=224)\n",
    "#         mtf_images[i] = mtf.fit_transform(data[i])\n",
    "\n",
    "#     return mtf_images\n",
    "# def mtf_tensor_save(data,memory=None):#memory 内存爆炸时使用\n",
    "#     #将变换后的tensor保存\n",
    "#     if memory==None:\n",
    "#         MTF_data=[]\n",
    "#         for i in range(data.shape[0]):\n",
    "#             mtf_data=data[i:i+1,:,:]\n",
    "#             mtf_images = MTF(mtf_data)\n",
    "#             MTF_data.append(mtf_images)\n",
    "\n",
    "#     else:\n",
    "#         part_size = data.shape[0] // memory\n",
    "#         for j in range(memory):\n",
    "#             MTF_data=[]\n",
    "#             start_idx = j * part_size\n",
    "#             end_idx = (j + 1) * part_size if j < memory - 1 else data.shape[0]\n",
    "#             part_data = data[start_idx:end_idx, :, :]\n",
    "#             for k in range(part_data.shape[0]):\n",
    "#                 mtf_data=part_data[k:k+1,:,:]\n",
    "#                 mtf_images = MTF(mtf_data)\n",
    "#                 MTF_data.append(mtf_images)\n",
    "#                 del mtf_images\n",
    "            \n",
    "#             del part_data\n",
    "#             output_path = os.path.join(base_path+'/processed_data/MTF', f'natural_train_MTF_{j}.pt')#更改路径\n",
    "#             torch.save(MTF_data, output_path)\n",
    "\n",
    "#     return MTF_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_natural_train = torch.load(base_path+'/tensor dataset/natural_train_dataset.pt')\n",
    "# natural_train_MTF=mtf_tensor_save(loaded_natural_train,memory=2)\n",
    "# del loaded_natural_train,natural_train_MTF\n",
    "# loaded_natural_test = torch.load(base_path+'/tensor dataset/natural_test_dataset.pt')\n",
    "# natural_test_MTF=mtf_tensor_save(loaded_natural_test)\n",
    "# torch.save(natural_test_MTF, base_path+'/processed_data/MTF/natural_test_MTF.pt')\n",
    "# del loaded_natural_test,natural_test_MTF\n",
    "# loaded_ep_train = torch.load(base_path+'/tensor dataset/ep_train_dataset.pt')\n",
    "# ep_train_MTF=mtf_tensor_save(loaded_ep_train)\n",
    "# torch.save(ep_train_MTF, base_path+'/processed_data/MTF/ep_train_MTF.pt')\n",
    "# del loaded_ep_train,ep_train_MTF\n",
    "# loaded_ep_test = torch.load(base_path+'/tensor dataset/ep_test_dataset.pt')\n",
    "# ep_test_MTF=mtf_tensor_save(loaded_ep_test)\n",
    "# torch.save(ep_test_MTF, base_path+'/processed_data/MTF/ep_test_MTF.pt')\n",
    "# del loaded_ep_test,ep_test_MTF\n",
    "# loaded_ss_train = torch.load(base_path+'/tensor dataset/ss_train_dataset.pt')\n",
    "# ss_train_MTF=mtf_tensor_save(loaded_ss_train)\n",
    "# torch.save(ss_train_MTF, base_path+'/processed_data/MTF/ss_train_MTF.pt')\n",
    "# del loaded_ss_train,ss_train_MTF\n",
    "# loaded_ss_test = torch.load(base_path+'/tensor dataset/ss_test_dataset.pt')\n",
    "# ss_test_MTF=mtf_tensor_save(loaded_ss_test)\n",
    "# torch.save(ss_test_MTF, base_path+'/processed_data/MTF/ss_test_MTF.pt')\n",
    "# del loaded_ss_test,ss_test_MTF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #可视化\n",
    "# sample_index = 0  # 选择一个样本进行展示\n",
    "\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# plt.imshow(mtf_images[sample_index][sample_index], cmap='viridis', origin='lower')\n",
    "# plt.title(f'MTF Image for Sample {sample_index}')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "格拉姆角场"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def GAF(data,method):\n",
    "#     num_samples,num_features, num_time_steps= data.shape\n",
    "#     gaf_images = np.zeros((num_samples, num_features, 128, 128))\n",
    "#     for i in range(num_samples):\n",
    "#         gaf = GramianAngularField(image_size=128,method=method)\n",
    "#         gaf_images[i] = gaf.fit_transform(data[i])\n",
    "#     return gaf_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = torch.load(base_path+'/tensor dataset/natural_test_dataset.pt')\n",
    "# GADF_data=[]\n",
    "# for i in range(data.shape[0]):\n",
    "#     gaf_data=data[i:i+1,:,:]\n",
    "#     # 调用函数进行 GAF 转换\n",
    "#     gaf_images_gadf = GAF(gaf_data,method='d')\n",
    "#     GADF_data.append(gaf_images_gadf)\n",
    "# GADF_data=torch.tensor(GADF_data).squeeze(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(torch.tensor(GADF_data).shape)\n",
    "# #可视化\n",
    "# sample_index = 70  # 选择一个样本进行展示\n",
    "\n",
    "# plt.figure(figsize=(13, 6))\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.imshow(GADF_data[sample_index][0], cmap='viridis', origin='lower')\n",
    "# plt.title(f'GASF Image for Sample {sample_index}')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def gaf_tensor_save(data,memory=None):#memory 内存爆炸时使用\n",
    "#     #将变换后的tensor保存\n",
    "#     if memory==None:\n",
    "#         GASF_data=[]\n",
    "#         GADF_data=[]\n",
    "#         for i in range(data.shape[0]):\n",
    "#             gaf_data=data[i:i+1,:,:]\n",
    "#             # 调用函数进行 GAF 转换\n",
    "#             gaf_images_gasf = GAF(gaf_data,method='s')\n",
    "#             gaf_images_gadf = GAF(gaf_data,method='d')\n",
    "\n",
    "#             GASF_data.append(gaf_images_gasf)\n",
    "#             GADF_data.append(gaf_images_gadf)\n",
    "\n",
    "#     else:\n",
    "#         part_size = data.shape[0] // memory\n",
    "#         for j in range(memory):\n",
    "#             GASF_data=[]\n",
    "#             GADF_data=[]\n",
    "#             start_idx = j * part_size\n",
    "#             end_idx = (j + 1) * part_size if j < memory - 1 else data.shape[0]\n",
    "#             part_data = data[start_idx:end_idx, :, :]\n",
    "#             for k in range(part_data.shape[0]):\n",
    "#                 gaf_data=part_data[k:k+1,:,:]\n",
    "#                 # 调用函数进行 GAF 转换\n",
    "#                 gaf_images_gasf = GAF(gaf_data,method='s')\n",
    "#                 GASF_data.append(gaf_images_gasf)\n",
    "#                 del gaf_images_gasf\n",
    "            \n",
    "#                 gaf_images_gadf = GAF(gaf_data,method='d')\n",
    "#                 del gaf_data\n",
    "#                 GADF_data.append(gaf_images_gadf)\n",
    "#                 del gaf_images_gadf\n",
    "#             del part_data\n",
    "\n",
    "#             output_path_GADF = os.path.join(base_path+'/processed_data/GADF', f'natural_train_GADF_{j}.pt')#更改路径\n",
    "#             torch.save(GADF_data, output_path_GADF)\n",
    "#             output_path_GASF = os.path.join(base_path+'/processed_data/GASF', f'natural_train_GASF_{j}.pt')#更改路径\n",
    "#             torch.save(GASF_data, output_path_GASF)\n",
    "#     return GASF_data,GADF_data        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #直接加载natural_train张量会引起内存错误 疑似过大  故分批处理 更改memory参数实现\n",
    "# loaded_natural_train = torch.load(base_path+'/tensor dataset/natural_train_dataset.pt')\n",
    "# gaf_tensor_save(loaded_natural_train,memory=2)\n",
    "# del loaded_natural_train\n",
    "\n",
    "# loaded_natural_test = torch.load(base_path+'/tensor dataset/natural_test_dataset.pt')\n",
    "# natural_test_GASF,natural_test_GADF=gaf_tensor_save(loaded_natural_test)\n",
    "# torch.save(natural_test_GASF, base_path+'/processed_data/GASF/natural_test_GASF.pt')\n",
    "# torch.save(natural_test_GADF, base_path+'/processed_data/GADF/natural_test_GADF.pt')\n",
    "# del loaded_natural_test,natural_test_GASF,natural_test_GADF\n",
    "\n",
    "# loaded_ep_train = torch.load(base_path+'/tensor dataset/ep_train_dataset.pt')\n",
    "# ep_train_GASF,ep_train_GADF=gaf_tensor_save(loaded_ep_train)\n",
    "# torch.save(ep_train_GASF, base_path+'/processed_data/GASF/ep_train_GASF.pt')\n",
    "# torch.save(ep_train_GADF, base_path+'/processed_data/GADF/ep_train_GADF.pt')\n",
    "# del loaded_ep_train,ep_train_GASF,ep_train_GADF\n",
    "\n",
    "# loaded_ep_test = torch.load(base_path+'/tensor dataset/ep_test_dataset.pt')\n",
    "# ep_test_GASF,ep_test_GADF=gaf_tensor_save(loaded_ep_test)\n",
    "# torch.save(ep_test_GASF, base_path+'/processed_data/GASF/ep_test_GASF.pt')\n",
    "# torch.save(ep_test_GADF, base_path+'/processed_data/GADF/ep_test_GADF.pt')\n",
    "# del loaded_ep_test,ep_test_GASF,ep_test_GADF\n",
    "\n",
    "# loaded_ss_train = torch.load(base_path+'/tensor dataset/ss_train_dataset.pt')\n",
    "# ss_train_GASF,ss_train_GADF=gaf_tensor_save(loaded_ss_train)\n",
    "# torch.save(ss_train_GASF, base_path+'/processed_data/GASF/ss_train_GASF.pt')\n",
    "# torch.save(ss_train_GADF, base_path+'/processed_data/GADF/ss_train_GADF.pt')\n",
    "# del loaded_ss_train,ss_train_GASF,ss_train_GADF\n",
    "\n",
    "# loaded_ss_test = torch.load(base_path+'/tensor dataset/ss_test_dataset.pt')\n",
    "# ss_test_GASF,ss_test_GADF=gaf_tensor_save(loaded_ss_test)\n",
    "# torch.save(ss_test_GASF, base_path+'/processed_data/GASF/ss_test_GASF.pt')\n",
    "# torch.save(ss_test_GADF, base_path+'/processed_data/GADF/ss_test_GADF.pt')\n",
    "# del loaded_ss_test,ss_test_GASF,ss_test_GADF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #可视化\n",
    "# sample_index = 0  # 选择一个样本进行展示\n",
    "\n",
    "# plt.figure(figsize=(13, 6))\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.imshow(gaf_images_gasf[sample_index][sample_index], cmap='viridis', origin='lower')\n",
    "# plt.title(f'GASF Image for Sample {sample_index}')\n",
    "\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.imshow(gaf_images_gadf[sample_index][sample_index], cmap='viridis', origin='lower')\n",
    "# plt.title(f'GADF Image for Sample {sample_index}')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
